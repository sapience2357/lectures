{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.4.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /root/anaconda3/envs/tensorflow37/lib/python3.7/site-packages\n",
      "Requires: absl-py, wheel, tensorflow-estimator, flatbuffers, protobuf, numpy, six, termcolor, gast, wrapt, astunparse, grpcio, tensorboard, google-pasta, h5py, keras-preprocessing, typing-extensions, opt-einsum\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일반적인 선형회귀 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model\n",
    "- 1차 함수\n",
    "- 선형성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형모델에 대한 여러가지 표현\n",
    "\n",
    "- 단순선형\n",
    "$$\n",
    "\\begin{align*}\n",
    "    f(x) &= b + ax \\\\\n",
    "    f(x) &= w_0 + w_1x \\\\\n",
    "    f(x) &= \\beta_0 + \\beta_1x \\\\\n",
    "    f(x) &= X^{T}B\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- 다중선형\n",
    "$$\n",
    "\\begin{align*}\n",
    "    f(x) &= \\beta_0 \\cdot 1 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_n \\\\\n",
    "    f(x) &= [1, x_1, x_2, ... , x_n] \n",
    "    \\begin{bmatrix}\n",
    "        \\beta_0 \\\\\n",
    "        \\beta_1 \\\\\n",
    "        \\beta_2 \\\\\n",
    "        ... \\\\\n",
    "        \\beta_n\n",
    "    \\end{bmatrix} \\\\\n",
    "    f(x) &= X\\cdot B \\\\\n",
    "    f(x) &= [x_1, x_2, ... , x_n] \n",
    "    \\begin{bmatrix}\n",
    "        \\beta_1 \\\\\n",
    "        \\beta_2 \\\\\n",
    "        ... \\\\\n",
    "        \\beta_n\n",
    "    \\end{bmatrix} + b\\\\\n",
    "    f(x) &= X\\cdot B + b\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float64)\n",
    "y = np.array([0, -1, -3, -3], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(beta, x, y):\n",
    "    yhat = beta[0] + beta[1] * x\n",
    "    # yhat = np.dot(x, beta)\n",
    "    return np.mean((y - yhat) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss(beta, x, y):\n",
    "    n = len(x)\n",
    "    val = np.array([0., 0.])\n",
    "    for i in range(n):\n",
    "        error = beta[0] + beta[1] * x[i] - y[i]\n",
    "        val += 2.0 * error * np.array([1.0, x[i]]) / n\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화(gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.035 -0.115] 3.4255375\n",
      "[-0.06355 -0.211  ] 2.5060663524999995\n",
      "[-0.086729  -0.2911725] 1.8676128538753747\n",
      "[-0.10543579 -0.35816017] 1.4241542579798327\n",
      "[-0.12041907 -0.41416436] 1.116001185187483\n",
      "[-0.13230247 -0.46101875] 0.9017364218329584\n",
      "[-0.14160548 -0.50025082] 0.7526214237021915\n",
      "[-0.14876083 -0.53313292] 0.6487151071519776\n",
      "[-0.15412897 -0.56072494] 0.5761807603863539\n",
      "[-0.15801014 -0.58390975] 0.5254173661714167\n"
     ]
    }
   ],
   "source": [
    "maxIter = 10\n",
    "learning_rate = 0.01\n",
    "beta0 = np.array([0., 0.])\n",
    "\n",
    "for i in range(maxIter):\n",
    "    grad = grad_loss(beta0, x, y)\n",
    "    beta1 = beta0 - learning_rate * grad\n",
    "    beta0 = beta1\n",
    "    print(beta0, mse(beta0, x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우를 이용한 선형회귀 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3,4], dtype=tf.float64)\n",
    "y = tf.constant([0, -1, -3, -3], dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable([0], dtype=tf.float64) # 기울기, beta1, 변수의 영향력\n",
    "b = tf.Variable([0], dtype=tf.float64) # y-절편, beta0, bias(편향), 상수항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수, 최적화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(x):\n",
    "    return b + a * x\n",
    "\n",
    "def mse(yhat, y):\n",
    "    return tf.reduce_mean(tf.pow(yhat - y, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적화 과정(학습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 3.425537526909821, a: [-0.211], b: [-0.06355]\n",
      "step: 1, loss: 2.5060663898646043, a: [-0.29117249], b: [-0.086729]\n",
      "step: 2, loss: 1.8676128927953963, a: [-0.35816017], b: [-0.10543579]\n",
      "step: 3, loss: 1.4241542940276417, a: [-0.41416435], b: [-0.12041907]\n",
      "step: 4, loss: 1.116001216503328, a: [-0.46101875], b: [-0.13230247]\n",
      "step: 5, loss: 0.9017364479676788, a: [-0.50025081], b: [-0.14160548]\n",
      "step: 6, loss: 0.7526214449278392, a: [-0.53313291], b: [-0.14876083]\n",
      "step: 7, loss: 0.6487151240623148, a: [-0.56072493], b: [-0.15412897]\n",
      "step: 8, loss: 0.5761807736743624, a: [-0.58390974], b: [-0.15801014]\n",
      "step: 9, loss: 0.525417376512874, a: [-0.60342278], b: [-0.16065445]\n"
     ]
    }
   ],
   "source": [
    "maxIter = 10\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "for i in range(maxIter):\n",
    "    \n",
    "    # 기울기\n",
    "    with tf.GradientTape() as grad:\n",
    "        yhat = linear_model(x)\n",
    "        loss = mse(yhat, y)\n",
    "        \n",
    "    # 기울기 계산\n",
    "    gradients = grad.gradient(loss, [a, b])\n",
    "    \n",
    "    # a, b를 업데이트 \n",
    "    optimizer.apply_gradients(zip(gradients, [a, b]))\n",
    "    \n",
    "    print('step: {}, loss: {}, a: {}, b: {}'.format(i, loss, a.numpy(), b.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow37",
   "language": "python",
   "name": "tensorflow37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
