# 최적화 과정 

- numpy를 이용한 선형회귀
- 아이스크림 문제를 풀었었죠 ... 



# 예측 Vs. 분류 모형

- 대표적인 지도기반의 학습 알고리즘
- 반응변수의 형태에 따른 차이
  - 반응변수 y가 이산형 이라면 분류 모형(예. 타이타닉, 스팸메일, ... )
  - 반응변수 y가 연속형 이라면 예측 모형(예. 자전거 대여, ... )
- 아이스크림과 같은 예제는 예측 모형이라고 볼 수 있겠죠 
  - 온도에 따른 아이스크림 판매량을 가정했었죠, 반응변수 y가 연속형 이었다는 거죠
  - numpy를 사용해서 손실함수를 정의하고 손실함수의 함수값이 가장 작아지는 방향으로 최적화 과정을 진행
  - 손실함수(오참함수, 비용함수)의 함수값이 가장 작아진다는 것은 손실이 최소화 된다라는 뜻이죠 
  - 즉, 손실이 최소화 된다는 것은, 가장 최적화된 선을 그린다는 거죠(선형적인 관계가 있을걸다 라고 가정)



# R 에서의 선형회귀

- 반응변수가 연속형(실수형)인 경우를 예측 모형이라고 하고, 
- Regression이라고 표현 합니다. 
- 아이시크림의 예제인 경우 

> x를 온도, y를 아이스크림의 판매량이라고 가정
>
> 일반적으로 온도가 오르면, 사람들이 아이스크림을 많이 사 먹을 것이다(그림으로 확인)
>
> 즉, 온도와 아이스크림의 판매량 사이에는 선형적으로 비례하는 관계가 있을거야(그림으로 확인)
>
> 그래서 우리는 다음과 같이 선형적인 관계가 있을것으로 가정하고 

$$
	y = b + ax
$$

> 최적화 과정을 통해서 b, a를 추정 했습니다. 



## L1 loss

- Least absolute deviation 라고 합니다. 

$$
L = \sum_{i=1}^n|y_i - \hat y_i| = \sum_{i=1}^n|y_i - (b + a_ix_i)|
$$

- 주어진 데이터 Y와 예측된 데이터 Y 사이의 거리의 총합
- 미분이 불가능하기 때문에 최적화 문제를 풀기 어려운 문제가 있다.



## 다음과 같이 키를 조사한 자료가 있다고 하자. 

| 1    | 2     | 3     | 4     | 5     | 6     | 7    | 8     | 9     | 10   | 11    | 12    | 13    | 14    | 15    | 16    | 17   | 18    | 19    | 20   |
| ---- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- |
| 169  | 166.5 | 171.6 | 177.5 | 169.8 | 175.4 | 176  | 172.1 | 172.7 | 173  | 183.1 | 180.5 | 173.6 | 174.5 | 174.6 | 165.8 | 170  | 176.4 | 171.7 | 174  |

- 손실함수를 어떻게 정의할까? 
- 키의 중심에 대한 모수를 추정할 때, L1 손실을 최소화 하는 방향으로 추정
- 손실함수는 다음과 같이 나타낼 수 있다. 

$$
\mathbb{X} = \left\{ x_1, \cdots , x_n \right\} \\

L1(\mu) = \sum_{i=1}^n|x_i - \mu|
$$

## L2 loss

- Leaste Squares라고 합니다. 
- 최소제곱추정
- Mean Squared Error(MSE)라고도 부릅니다. 

$$
L = \sum_{i=1}^n(y_i - \hat y_i)^2 = \sum_{i=1}^n(y_i - (b + a_ix_i))^2
$$

## 다음과 같이 키를 조사한 자료가 있다고 하자. 

| 1    | 2     | 3     | 4     | 5     | 6     | 7    | 8     | 9     | 10   | 11    | 12    | 13    | 14    | 15    | 16    | 17   | 18    | 19    | 20   |
| ---- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- | ----- | ----- | ----- | ----- | ----- | ----- | ---- | ----- | ----- | ---- |
| 169  | 166.5 | 171.6 | 177.5 | 169.8 | 175.4 | 176  | 172.1 | 172.7 | 173  | 183.1 | 180.5 | 173.6 | 174.5 | 174.6 | 165.8 | 170  | 176.4 | 171.7 | 174  |

- 손실함수를 어떻게 정의할까? 
- 키의 중심에 대한 모수를 추정할 때, L1 손실을 최소화 하는 방향으로 추정
- 손실함수는 다음과 같이 나타낼 수 있다. 

$$
\mathbb{X} = \left\{ x_1, \cdots , x_n \right\} \\

L2(\mu) = \sum_{i=1}^n(x_i - \mu)^2
$$



## 예측 모형에 대한 최적화 과정



### 미세먼지와 차량통행 데이터 

- 미세먼지 농도와 차량의 통행량 간의 관계가 있을지... 
- 회귀모형을 적합해서 확인해 봅시다. 

- 손실함수를 어떻게 정의할 것인가? 선형적으로 가정 
  - 차가 많이 다니는 날에(통행량이 많은 날)에 미세먼지 농도 또한 높아질 것인가? 
  - 즉, 통행량이 많은 날에는 미세먼지 농도 또한 높을 것이라고 가정

- 반응변수 y는 미세먼지 농도
- 입력변수 x는 차량 통행량

$$
y = b + ax + \epsilon\\
	y = \beta_0 + \beta_1x + \epsilon \\
	y = \theta_0 + \theta_1x + \epsilon
$$

- 즉 우리는 베타0, 베타1 혹은 세타0, 세타1을 추정하는 문제로 생각해볼 수 있을 겁니다. 
- 이때, 손실 함수는 다음가 같이 정의해볼 수 있다. 

$$
L1(\beta_0, \beta_1) = \sum_{i=1}^n|y_i - (\beta_0 + \beta_1x_i)| \\
	L2(\beta_0, \beta_1) = \sum_{i=1}^n(y_i - (\beta_0 + \beta_1x_i))^2 \\
$$

- 이렇게 해 봤더니... 다음과 같이 결과가 나왔죠
  - L1 손실에서는 b0 = 1.2805..., b1 = 0.00023... 정도로 추정 되었고, 
  - L2 손실에서는 b0 = 1.2776..., b1 = 0.000196... 정도로 추정 되었다. 

$$
\hat Y = 1.2805 + 0.00023 \cdot X + \epsilon\\
	\hat Y = 1.2776 + 0.000196 \cdot X + \epsilon
$$

- X의 계수인 b1이 뜻하는 것은 기울기를 나타냅니다. 
- 이 얘기는 다시 말하자면, x가 1 증가 할 때, y는 0.00023 혹은 0.000196 만큼 증가함을 뜻하는 겁니다. 
- 두 가지 회귀 계수 모두 비슷한 값을 보여주고 있고, 이에 따르면 차량 통행량이 미세먼지 농동에 미치는 영향력은 매우 작음을 알 수 있죠



- lm()함수를 이용한 결과는 다음과 같다. 
  - b0(intercept) = -9.0.307001, b1 = 0.0003614 정도로 추정되었다. 
  - 이 결과는 앞의 L2 손실을 이용한 optim()함수를 사용한 결과와는 다르게 나왔다. 
  - optim()함수로 계산한 최소값이 실제 최소값이 아닌 local minimum(극소) 이기 때문이다. 
  - optim()함수의 초기값을 (1,1) 아닌 (0,0)으로 변경하면 동일한 값을 확인할 수 있다. 



### Scailing Problem

- 차량 통행과 미세먼지 농도 사이에는 정말 아무런 관계가 없을까? 
- 회귀계수가 0에 가깝게 나왔기 때문에, 그렇게 볼 수도 있다. 
- 농도 수치와 차량 통행량의 사이에는 단위가 굉장히 큰 것 같지 않나요? 
- 미세먼저 농도와 차량 통행량의 단위가 다르기 때문에 회귀계수가 작은 것처럼 보이게 된다. 
  - 실제로 미세먼지 농동가 50 정도라면 굉장히 높은 수치인데 
  - 차량 통행량에 비하면 아주 낮은 수치가 된다. 
- 자료의 평균을 빼주고(centering) 표준편차로 나눠주는 (scaling)과정을 통해 문제를 해결할 수 있다. 
- R에서 scale()함수를 이용할 수 있다. 
- 스케일을 사용해 단위를 통일해서 회구모형을 적합한 결과 다음과 같다. 
  - b0 = 7.507 * 10^10, b1 = 1.866 * 10^-1 
  - 자동차의 통행량이 어느 정도 유의한 영향을 주는 것 정도로는 확인이 된다.



### 회귀계수란? 

- 찾으려는 모수 정도로만 얘기를 했었어요

- 회귀계수가 가지는 의미는 

  - 입력변수 X가 반응변수 Y에 미치는 영향 정도로 생각을 해볼 수 있다. 
  - 즉, 입력변수 X가 1 증가할 때 마다, 회귀계수만큼 영향이 증가한다고 볼 수 있다.
  - 만일, 회귀계수가 음수라면 입력변수 X가 1증가할 때마다 회귀계수만큼 영향이 감소한다고 볼 수 있다. 

- 전체 데이터에서 회귀모형을 적합한 결과를 보면 

  - ncar 변수의 회귀계수가 ncar 하나만 가지고 회귀모형을 적합했을 때와 전체를 가지고 적합을 한 경우 
  - 회귀계수가 다르게 계산됨을 확인했다. 
  - 다변수 회귀분석을 진행하는 경우 각 변수들은 반드시 독립적이어야 한다. 
  - 독립적이라면 변수와 변수 사이의 관계가 전혀 없어야 한다. 즉, 변수가 다른 변수에 영향을 끼치면 안된다는 것을 의미

  > 다변수 회귀분석인 경우 회귀분석과 회귀계수의 해석은 신중하게 진행되어야 한다. 
  >
  > 어짜피 우리가 확인하는 값들은 전부 수치적으로 계산된 값일 뿐 ... 
  >
  > 실제 의미를 전혀 반영하지 못한다. (거짓말, 새빨간 거짓말, 그리고 통계)



# 선형회귀모형의 특징 

- 파이썬을 통한 선형회귀 수업에서도 다시 한 번 다룰겁니다. 
- 선형회귀모형과 같은 경우 해석이 아주 쉽고, 심지어 최적의 모수를 직접 계산할 수도 있다. 
- 그리고, 직관적으로 그 구조를 파악하기가 쉽다는 장점이 있다. 
- 때문에, 널리 사용이 됩니다. 
- 많은 통계적 모형들이 선형회귀모형을 응용한 형태로 사용을 해요 
  - 예를 들면 딥러닝 같은 경우 선형회귀모형에 활성함수를 씌운 것을 겹겹이 쌓아올려서 동작하는 구조
  - 그래서, 딥러닝을 그냥 선형회귀라고 부르는 사람들도 있습니다. 
  - 다만, 모수를 많이 늘려서 정확도를 높이는 방법이 딥러닝이다. 
- 선형회귀모형은 통계적 모형 에서도 가장 기본적이면서 가장 중요한 모형이라고 볼 수 있습니다. 
- 그래서, 수업 시간에 가장 많은 시간을 할애하는 것도 그 이유이다. 



# 실습 

1. 탐색적 자료 분석을 통해서 CO, NO2, ncar 변수와 관계를 확인해보자. 
2. 단순선형회귀 모형을 이용해 CO 변수와 ncar 변수 사이의 관계를 확인해보자. 
3. 선형회귀모형을 통해서 CO와 NO2, ncar 변수 사이의 관계를 확인해보자. 
4. 차량통행량이 80000, NO2 농도가 0.03 정도라면 CO 농도는 어느 정도로 예측될 수 있는 확인해보자. 





## 분류 모형에 대한 최적화 과정



### 스팸 메일 분류기

- 새로 도착한 메일이 스팸메일인지 아닌지를 분류하는 기계를 생각해보자. 
- 입력변수를 어떤걸로 할 것인가?는 매우 중요한 문제 이지만, ... 
- 메일에 있는 단어들로 일단 가정을 하겠습니다. 그렇다면 입력변수는 '메일의 단어들'이고, 
- 반응변수는 '스팸메일의 여부'인 '0, 1'이라고 할 수 있죠
- 우리가 메일에 자주 들어가는 단어들에 대한 목록을 가지고 있다고 하죠 
- 그리고 그 목록(리스트)에 들어있는 i번째의 단어가 메일이 들어 있다면, ... 

$$
x_i = 1\;or\;0 \\
	\mathbb{X} = \left\{ x_1, \cdots, x_{i}	\right\}
$$

- 이러한 입력 벡터 X를 생각해 볼 수 있을겁니다. 