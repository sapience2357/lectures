# 선형회귀(Linear Regression)

- numpy 라이브러리를 이용해서 아주 약간의 선형대수와 미분을 볼려고 하는 수업입니다! 
- numpy 라이브러리의 특징을 직접 사용하면서 충분히 익힐 수 있도록 합시다. 



# 이 수업의 목표

- 다음과 같은 형태의 해를 구하기 
- 이 문제를 어떻게 풀 것인가? 
- 이 문제를 왜 풀어야 되지? 

$$
\begin{equation}
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_3\\x_4
\end{bmatrix}=
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation}
$$



# 우리가 앞으로 해야 되는 것들



## 예를 들어 다음과 같은 자료가 있다면

| x    | 20   | 21   | 22   | 23   | 24   |
| ---- | ---- | ---- | ---- | ---- | ---- |
| y    | 15   | 16   | 21   | 33   | 42   |



## 일변수

- y에 미치는 영향을 주는 변수들이 한두개가 아닐 수 있지만
- 다변수에 대한 내용이 주를 이루겠지만, 변수 하나만 두고 진행 할 거에요
- x는 뭐든 될 수 있어요

> 예를 들면: 온도, 집평수, 지역, ... 



## 그래서 지금 주어진 데이터는 

- 온도에 따른 아이스크림 판매량을 가정하고 만든 데이터에요 
- 실제로는 직접 수집(관찰)된 데이터가 될 거에요, 그러니깐 수업 시간에는 이 데이터가 실제로 수집(관찰)된 데이터라고 가정 하겠습니다. 
- 주어진(이미 알고 있는) 데이터를 통해서, x와 y 사이의 관계를 알고 싶은거에요
- 그림을 그려서 X와 Y 사이의 관계를 볼 수 있는 경우는 굉장히 제한적이에요 
- 그래서 수업시간이나 다른 여러 책들을 보면 2차원, 3차원 그래프들을 그리는 이유가 
- 그릴 수 있을 때, 많이 그려보는 겁니다.  그래야 보이지 않을 때도,  어느정도 추상적으로나마 생각해볼 수 있게 말이죠 
- 근데 이게 말이 안되죠, 우리는 사실 상상조차 불가능 할 거에요 



## 함수를 찾고 싶은거죠

- X와 Y 사이에 존재하는 관계를 찾는다는 것은 함수를 찾는다는 것과 같은 얘기

$$
y = f(x)
$$

- 그러나, 주어진 데이터를 정말 잘(완벽히)설명할 수 있는 함수를 찾는 것은 정말 어려운 일이에요
- 하지만, 수학적으로는 증명이 되어 있어요 데이터의 갯수가 n이라면 `n-1`차 항 까지로 주어진 데이터를 완벽히 설명할 수 있는 다항함수는 존재
- 물론 그 함수가 새로 들어올(관찰되지 않은/수집되지 않은) 자료까지 정확하게 포함하느냐는 별개의 문제지만, ... 



## 문제를 더 쉽게 바꿔서 해결

- 함수를 찾는 문제는 너무 어려우니깐,  함수를 가정하고 진행

> 예를 들면 선형적인 관계가 있을거야 라고 가정 한다면
>
> 다음과 같이 함수를 정의할 수 있다. 
>
> 그럼 x와 y는 이미 알고 있으므로, a, b만 찾으면 되는 더 간단한 문제로 바꿔서 해결
>
> 모수적 추정이라고 얘기하고, 선형이라고 가정하고 모수적 추정을 하는 방법을 `선형회귀`라고 합니다. 

$$
y = b + ax
$$



## 주어진 아이스크림 문제를 어떻게 해결할까? 



### 선형적인 관계로 가정(모수적 추정)



1.  연립방정식으로 푸는 방법(가우스 소거법, ... )

$$
\begin{cases}
		15 = b + a \cdot 20 \\
		16 = b + a \cdot 21 \\
		21 = b + a \cdot 22 \\
		\vdots
		
	\end{cases}
$$



2. 선형대수식으로 풀기 

$$
\begin{bmatrix}
		15 \\ 16 \\ 21 \\ 33 \\ 42
	\end{bmatrix} =
	
	\begin{bmatrix}
		a \\ b
	\end{bmatrix} \cdot
	
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}
$$

- 행렬과 행렬간의 연산에도 대수적 법칙이 그대로 적용
- 교환법칙과 같은 경우는 성립을 안할수도 있지만 
- 역원, 항등원도 존재, 역행렬, 항등행렬도 존재(물론 항상 존재하지만 않지만,, )

$$
\begin{bmatrix}
		15 \\ 16 \\ 21 \\ 33 \\ 42
	\end{bmatrix} \cdot 
		\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}^{-1} = 
	
	\begin{bmatrix}
		a \\ b
	\end{bmatrix} \cdot
	
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix} \cdot
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}^{-1}
$$



- 해당 아이스크림 예제는 해가 없습니다. 
- 그럼 안풀리는 문제는요? 어떻게 해결 할 건데요? 
- 그게 핵심이죠! 
- 일단 풀리는 문제부터 플어볼게요 선형대수를 이용해서 



# 선형대수 풀이법

## 직접 풀이법(Direct Solve)

$$
\begin{equation}
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_3\\x_4
\end{bmatrix}=
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation}
$$

$$
\begin{equation}
\begin{bmatrix}
1\\2\\3\\4
\end{bmatrix}=
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}^{-1} \cdot 
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation} \\
$$



- 판별식(Determinant)의 값이 0이 아닌경우 
- 양변에 역행렬을 취해서 원하는 답을 구할 수 있다. 
- 역행렬이 존재하는 경우는 정방행렬(nXn)이어야 하고, 판별식의 값이 0이 아니어야 한다.



## 반복 풀이법(Iteration Solve)

- Jacobi Method
- Cojugate Gradient Method 



### conjugated Gradient Method



![](https://wikimedia.org/api/rest_v1/media/math/render/svg/fc68826758d3b5a9425434bd37540f1a24cd673f)



- 고차원의 풀리지 않는 문제들에 대해서 선형방정식을 이용해서 반복적으로 접근하는 방법으로 문제를 해결
- 즉, 고차원의 문제를 선형방정식의 단순화된 문제로 바꿔서 문제를 해결
- 단순화된 문제를 반복적으로 계산함으로 인해서 답을 근사(머신러닝에서는 이러한 접근을 `학습한다`라고 표현)

- 어쨋든, 선형방적식을 풀어야 한다는 문제는 남아 있게 된다. 
- 수학적으로 이 알고리즘을 접근하지는 않을거고, 파이썬으로 어떻게 구현되는지에 대해서만 애기를 해볼게요
- 너무 어렵게 생각하지 마시고, 복잡해 보이는 수식들이 파이썬으로 표현될 때, 얼마나 쉽게 구현되는지만 볼게요 
- 어렵지 않아요, ... 복잡해 보인다고 너무 겁먹을 필요는 없으시구요 ... 



# 왜 어려울까? 

- 파이썬에 익숙하지 않은 상태에서 ... 
- 방정식도 익숙하지 않은 상태에서 ... 
- 즉, 둘다 익숙하지 않은 상태에서 구현을 하려고 하면 어렵게 느껴질 수 밖에 없죠 .. 
- 자괴감을 갖지 않으셨으면 하는게 제 작은 소망입니다. ... 
- 내가 멍청하다거나, 이해력이 딸린다, ... 절대 그렇지 않아요 
- 저도 수포자 였어요 ... 지금도 잘 못해요 필요한 내용만 어떻게, 어떻게, ... 하다보니 



# 아이스크림 문제 풀기 

- 선형적인 관계로 가정(모수적 추정)

$$
y = b + ax
$$

- 우리가 추정하려는 모수는 a, b가 되는 거죠
- 자 그럼 주어진 자료에 대해서 최적화된(가장 잘 설명할 수 있는) 선은 무엇일까? 
- 가장 최적화된 선의 y-절편과 기울기를 찾으려고 하는 것이니깐요 ... 



## 에러, 손실, 비용, ... 함수

- error function, loss function, cost function, ... 
- 오차함수, 손실함수, 비용함수, 등으로 불러요 다 같은 얘기에요 

- 최적화된 선이라는 것은 주어진 값과 예측된 값 사이의 오차가 가장 작은 선이라는 뜻 
- 이 때, 그 오차를 정의한 함수를 (오차, 손실, 비용) 함수 등으로 부릅니다. 

- 오차를 정확히 측정하기 위한 방법
  - 오차의 절대값의 총합 
  - 오차의 제곱의 총합(Squared Error, Mean Squared Error)



## 오차함수의 정의

- 선형적인 관계로 가정
- 다음과 같이 오차 함수를 정의할 수 있을 것이다. 

$$
error(a, b) = \min_{a,b}\sum_{i=1}^n(Y_i - (ax_i + b))^2
$$

- 그럼 우리는 이 함수의 값이 가장 작아지는 a와 b를 찾고 싶은거죠
  - 함수의 값이 가장 작다는 것은 오차가 가장 작다는 의미와 동일

$$
error(a, b) = \underset{a, b}{\mathrm{argmin}}\sum_{i=1}^n(Y_i - (ax_i + b))^2
$$

- 즉, 오차함수의 함수값을 가장 작아지게 하는 인자 a와 b를 찾겠다는 거죠

- 여기서 문제는 해가 있을수도 있고, 없을수도 있다는 것
- 해가 없으면? 해에 근사하는 방법을 취하는 거죠



# 미분이란? 

- 함수의 기울기를 나타낸다. 
- 기울기는 함수의 변화량을 나타낸다. 
- 직선에서는 우리가 미분을 얘기하지 않습니다. 
- 미분을 구할 수 없어요 .. 



## 곡선에서의 변화량은? 

- 변화량은 구간에서의 직선의 기울기 이다. 
- 변화량을 측정하는 구간마다 기울기가 다르다. 
- 평균 변화량

$$
\frac{\Delta y}{\Delta x} = \frac{f(b) - f(a)}{b - a} = \frac{f(a + \Delta x) - f(a)}{\Delta x}
$$

- 평균변화율이라고 하기에는 측정하는 구간이 너무 크다. 
- 충분히 작은 구간에서의 평균 변화율
- 얼마나 작으면 충분히 작다고 얘기할 수 있는가? 
- 순간의 변화율
- x의 변화량을 0.01 정도로 놓고 계산하면? 

$$
df(x) = \frac{f(x + 0.01) - f(x)}{0.01}
$$



- f(x) =  x^2일 때, 순간변화율은 2x로 알려져 있다. 
- x = 3일 때, 순간변화율은?  6이다. 

$$
	df(3) = \frac{f(3 + 0.01) - f(3)}{0.01} = \frac{3.01^2 - 3^2}{0.01} = \frac{0.0601}{0.01} = 6.01
$$

- 실제 순간 변화율과 비교해보면 오차가 있음을 알 수 있다. 
- 즉, 0.01 정도의 변화량도 충분히 작다고 얘기할 수 없다. 즉, 순간변화율 이라고는 얘기할 수 없다. 
- 0.001, 0.0000001, 0.000000000000001, ...  얼마나 작게 해도 오차는 계속 발생
- 그럼 어느 정도로 작아야 순간변화율인데? ... 



# 미분의 정의 

- 극한의 개념을 사용
- 수렴, 극한, 급수, 유리수의 조밀성, 완비성 공리, ... 

$$
f'(a) = \lim_{b \rightarrow a} \frac{f(b) - f(a)}{b-a} = \lim_{\Delta x \rightarrow 0}\frac{f(x+\Delta x) - f(x)}{\Delta x}
$$

- 분모를 순간에 이를 정도로(극한) 작게 만들면 순간변화율 이라고 얘기하고, 
- 극한이 존재한다면 이 극한값에 대한 평균변화율을 `순간변화율` `미분계수` 라고 한다. 
- 순간의 변화율은 그 위치에서의 접선의 기울기로 해석될 수 있다. 
- 미순계수를 함수로 하면 `도함수`라고 하고, 수식으로는 

$$
f'(x)
$$



# 다항함수의 미분

- 기본적인 함수, 다항함수, 지수함수, 로그함수, 삼각함수
- 수업 시간에는 다항함수의 미분만 살펴볼거고요 
- 나머지는 sympy를 이용해서 아주 간단하게 `미분계수`를 구하는 실습을 해볼 겁니다. 
- 다음의 다항함수의 미분계수를 구해봅시다. 

$$
f(x) = x^2
$$



## 미분의 정의에 의하여

$$
\lim_{\Delta x \rightarrow 0} \frac{f(x + \Delta x) - f(x)}{\Delta x} = \lim_{\Delta x \rightarrow 0} \frac{(x + \Delta x)^2 - x^2}{\Delta x} = \lim_{\Delta x \rightarrow 0} \frac{x^2 + 2\Delta x(x) + \Delta x^2 - x^2}{\Delta x} = \lim_{\Delta x \rightarrow 0} \frac{\Delta x(2x + \Delta x)}{\Delta x} = 2x
$$





# 우리가 미분을 이해해야 하는 이유

- 우리는 오차함수(손실함수, 비용함수, ...)의 함수값이 가장 작아지게 하는 인자를 찾고 싶은거에요 ... 
- 오차함수의 함수값이 가장 작다라는 것은 오차가 가장 작다는 얘기이죠 
- 오차가 가장 작을 때의 인자 a, b를 구하면, 오차가 가장 작은 선을 그릴 수 있구요 
- 그 선은 주어진 자료에 최적화된 선이라고 얘기할 수 있다. 
- 해가 존재한다면 그냥 방정식을 풀면 되겠지만, 해가 없다면, ... 
- 해를 찾을 수 없으면 해에 가장 가깝게 근사하고 싶은거죠 
- 어떻게 근사해요? 오차함수의 도함수의 함수값이(즉, 기울기가) 가장 작아지는 방향으로 근사하면 된다는 거죠 
- 도함수의 값(접선의 기울기)가 0이 된다면 해가 존재, 해가 존재하지 않으면 기울기가 가장 작아지는 
- 방향으로 근사하겠다 ...



## 최급하강법(Steepest Descent) 혹은 경사하강법(Gradient Descent)

- 머신러닝과 딥러닝에서 사용하는 최적화 방법
- 텐서플로우는 해당 최적화 방법 외에 다른 방법은 제공하지 않아요 ... 

- 수식으로는 다음과 같이 표현한다. 

$$
	x^{k+1} = x^{k} - \alpha \nabla f(x)
$$



# 편미분

- 함수 y의 변화량을 얘기할 때, 영향을 주는 요소가 2개 이상이면, 
- 함수 y의 변화량을 찾기가 너무 어려워지는거죠 
- 왜냐면, 두 개 이상의 변수가 계속 변하기 때문에, ... 
- 축을 고정한 상태에서(변하지 않는다고 가정) 변화율을 얘기하는건 쉬워지는 거죠 



# 그러나...

- 여기까지 저희는 해가 없는 경우에도 손실함수를 최소로 하는 인자를 찾을 수 있었습니다.(근사하는 방법)
- 항상 이렇게 좋은 상황이 발생하지는 않아요 ... 
- 우리가 수업시간이기 때문에 가장 이해하기 편한 내용으로 확인을 했기 때문인데 
- 실제 데이터들은 절대 이렇게 잘 동작하지 않습니다. 
- 근데, 왜 이런 잘 되는 상황만을 보느냐 



## 이론과 실제의 차이

- 실제 존재하는 모든 데이터에 대해서 전부 검증하고 이론화 시키는것은 불가능 
- 그래서 이론적으로는 가장 일반화된 형태를 가정하고 검증 및 확인을 합니다. 
- 잘 안되지만(실제와는 차이가 있지만), 잘되는 상황 하나정도는 만들어 놓는거에요 
- 예를 들어서 잘 동작하는 상황 조차도 없다면, 아예 쓸수 없는거죠



# 저희는 지금 ... 

- 저희는 지금 일변수일 때의 함수를 보고 있습니다. 
- 변수의 차원이 하나라면, ... 
- 좋은 점은 직관적으로 해가 존재하는지 혹은, 근사가 잘 되고 있는지 등등의 내용을 다 확인이 가능하죠!
- 내용도 쉽고요
- 그런데 변수가 3개 이상이라면, ... 이제부터는 우리가 그림을 그릴 수 없는 영역입니다. 
- 그리고 우리가 다루게 될 자료는 대부분 고차원의 자료가 대부분일 거에요 ... 
- 즉, 우리는 거의 대부분의 그림을 그려볼 수 없어요 
- 그림을 그려볼 수 없기 때문에, 출력되는 손실함수의 값만 보고 추정해야 되요(잘 되고 있는지...)
- 그래서 지금 하는 수업은 그림을 그려볼 수 있을때 손실함수의 특성을 최대한 확인해보고자 한다. 





















