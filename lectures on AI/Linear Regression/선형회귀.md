# 선형회귀(Linear Regression)

- numpy 라이브러리를 이용해서 아주 약간의 선형대수와 미분을 볼려고 하는 수업입니다! 
- numpy 라이브러리의 특징을 직접 사용하면서 충분히 익힐 수 있도록 합시다. 


# 이 수업의 목표

- 다음과 같은 형태의 해를 구하기 
- 이 문제를 어떻게 풀 것인가? 
- 이 문제를 왜 풀어야 되지? 

$$
\begin{equation}
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_3\\x_4
\end{bmatrix}=
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation}
$$



# 우리가 앞으로 해야 되는 것들



## 예를 들어 다음과 같은 자료가 있다면

| x    | 20   | 21   | 22   | 23   | 24   |
| ---- | ---- | ---- | ---- | ---- | ---- |
| y    | 15   | 16   | 21   | 33   | 42   |



## 일변수

- y에 미치는 영향을 주는 변수들이 한두개가 아닐 수 있지만
- 다변수에 대한 내용이 주를 이루겠지만, 변수 하나만 두고 진행 할 거에요
- x는 뭐든 될 수 있어요

> 예를 들면: 온도, 집평수, 지역, ... 



## 그래서 지금 주어진 데이터는 

- 온도에 따른 아이스크림 판매량을 가정하고 만든 데이터에요 
- 실제로는 직접 수집(관찰)된 데이터가 될 거에요, 그러니깐 수업 시간에는 이 데이터가 실제로 수집(관찰)된 데이터라고 가정 하겠습니다. 
- 주어진(이미 알고 있는) 데이터를 통해서, x와 y 사이의 관계를 알고 싶은거에요
- 그림을 그려서 X와 Y 사이의 관계를 볼 수 있는 경우는 굉장히 제한적이에요 
- 그래서 수업시간이나 다른 여러 책들을 보면 2차원, 3차원 그래프들을 그리는 이유가 
- 그릴 수 있을 때, 많이 그려보는 겁니다.  그래야 보이지 않을 때도,  어느정도 추상적으로나마 생각해볼 수 있게 말이죠 
- 근데 이게 말이 안되죠, 우리는 사실 상상조차 불가능 할 거에요 



## 함수를 찾고 싶은거죠

- X와 Y 사이에 존재하는 관계를 찾는다는 것은 함수를 찾는다는 것과 같은 얘기

$$
	y = f(x)
$$

- 그러나, 주어진 데이터를 정말 잘(완벽히)설명할 수 있는 함수를 찾는 것은 정말 어려운 일이에요
- 하지만, 수학적으로는 증명이 되어 있어요 데이터의 갯수가 n이라면 `n-1`차 항 까지로 주어진 데이터를 완벽히 설명할 수 있는 다항함수는 존재
- 물론 그 함수가 새로 들어올(관찰되지 않은/수집되지 않은) 자료까지 정확하게 포함하느냐는 별개의 문제지만, ... 



## 문제를 더 쉽게 바꿔서 해결

- 함수를 찾는 문제는 너무 어려우니깐,  함수를 가정하고 진행

> 예를 들면 선형적인 관계가 있을거야 라고 가정 한다면
>
> 다음과 같이 함수를 정의할 수 있다. 
>
> 그럼 x와 y는 이미 알고 있으므로, a, b만 찾으면 되는 더 간단한 문제로 바꿔서 해결
>
> 모수적 추정이라고 얘기하고, 선형이라고 가정하고 모수적 추정을 하는 방법을 `선형회귀`라고 합니다. 

$$
y = b + ax
$$



## 주어진 아이스크림 문제를 어떻게 해결할까? 



### 선형적인 관계로 가정(모수적 추정)



1.  연립방정식으로 푸는 방법(가우스 소거법, ... )

$$
	\begin{cases}
		15 = b + a \cdot 20 \\
		16 = b + a \cdot 21 \\
		21 = b + a \cdot 22 \\
		\vdots
		
	\end{cases}
$$



2. 선형대수식으로 풀기 

$$
\begin{bmatrix}
		15 \\ 16 \\ 21 \\ 33 \\ 42
	\end{bmatrix} =
	
	\begin{bmatrix}
		a \\ b
	\end{bmatrix} \cdot
	
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}
$$

- 행렬과 행렬간의 연산에도 대수적 법칙이 그대로 적용
- 교환법칙과 같은 경우는 성립을 안할수도 있지만 
- 역원, 항등원도 존재, 역행렬, 항등행렬도 존재(물론 항상 존재하지만 않지만,, )

$$
\begin{bmatrix}
		15 \\ 16 \\ 21 \\ 33 \\ 42
	\end{bmatrix} \cdot 
		\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}^{-1} = 
	
	\begin{bmatrix}
		a \\ b
	\end{bmatrix} \cdot
	
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix} \cdot
	\begin{bmatrix}
		20 \\ 21 \\ 22 \\ 23 \\ 24
	\end{bmatrix}^{-1}
$$



- 해당 아이스크림 예제는 해가 없습니다. 
- 그럼 안풀리는 문제는요? 어떻게 해결 할 건데요? 
- 그게 핵심이죠! 
- 일단 풀리는 문제부터 플어볼게요 선형대수를 이용해서 



# 선형대수 풀이법

## 직접 풀이법(Direct Solve)

$$
\begin{equation}
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}
\begin{bmatrix}
x_1\\x_2\\x_3\\x_4
\end{bmatrix}=
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation}
$$

$$
\begin{equation}
\begin{bmatrix}
1\\2\\3\\4
\end{bmatrix}=
\begin{bmatrix}
1 & 4 & 2 & 0 \\
9 & 5 & 0 & 0 \\
4 & 0 & 2 & 4 \\
6 & 1 & 8 & 3
\end{bmatrix}^{-1} \cdot 
\begin{bmatrix}
15\\19\\26\\44
\end{bmatrix}
\end{equation} \\
$$



- 판별식(Determinant)의 값이 0이 아닌경우 
- 양변에 역행렬을 취해서 원하는 답을 구할 수 있다. 
- 역행렬이 존재하는 경우는 정방행렬(nXn)이어야 하고, 판별식의 값이 0이 아니어야 한다.



## 반복 풀이법(Iteration Solve)

- Jacobi Method
- Cojugate Gradient Method 



### coujugated Gradient Method



![](https://wikimedia.org/api/rest_v1/media/math/render/svg/fc68826758d3b5a9425434bd37540f1a24cd673f)



- 고차원의 풀리지 않는 문제들에 대해서 선형방정식을 이용해서 반복적으로 접근하는 방법으로 문제를 해결
- 즉, 고차원의 문제를 선형방정식의 단순화된 문제로 바꿔서 문제를 해결
- 단순화된 문제를 반복적으로 계산함으로 인해서 답을 근사(머신러닝에서는 이러한 접근을 `학습한다`라고 표현)

- 어쨋든, 선형방적식을 풀어야 한다는 문제는 남아 있게 된다. 
- 수학적으로 이 알고리즘을 접근하지는 않을거고, 파이썬으로 어떻게 구현되는지에 대해서만 애기를 해볼게요
- 너무 어렵게 생각하지 마시고, 복잡해 보이는 수식들이 파이썬으로 표현될 때, 얼마나 쉽게 구현되는지만 볼게요 
- 어렵지 않아요, ... 복잡해 보인다고 너무 겁먹을 필요는 없으시구요 ... 

# 왜 어려울까? 

- 파이썬에 익숙하지 않은 상태에서 ... 
- 방정식도 익숙하지 않은 상태에서 ... 
- 즉, 둘다 익숙하지 않은 상태에서 구현을 하려고 하면 어렵게 느껴질 수 밖에 없죠 .. 
- 자괴감을 갖지 않으셨으면 하는게 제 작은 소망입니다. ... 
- 내가 멍청하다거나, 이해력이 딸린다, ... 절대 그렇지 않아요 
- 저도 수포자 였어요 ... 지금도 잘 못해요 필요한 내용만 어떻게, 어떻게, ... 하다보니 

# 아이스크림 문제 풀기 

- 선형적인 관계로 가정(모수적 추정)

$$
	y = b + ax
$$

- 우리가 추정하려는 모수는 a, b가 되는 거죠
- 자 그럼 주어진 자료에 대해서 최적화된(가장 잘 설명할 수 있는) 선은 무엇일까? 
- 가장 최적화된 선의 y-절편과 기울기를 찾으려고 하는 것이니깐요 ... 

## 에러, 손실, 비용, ... 함수

- error function, loss function, cost function, ... 
- 오차함수, 손실함수, 비용함수, 등으로 불러요 다 같은 얘기에요 

- 최적화된 선이라는 것은 주어진 값과 예측된 값 사이의 오차가 가장 작은 선이라는 뜻 
- 이 때, 그 오차를 정의한 함수를 (오차, 손실, 비용) 함수 등으로 부릅니다. 

- 오차를 정확히 측정하기 위한 방법
  - 오차의 절대값의 총합 
  - 오차의 제곱의 총합(Squared Error, Mean Squared Error)

## 오차함수의 정의

- 선형적인 관계로 가정
- 다음과 같이 오차 함수를 정의할 수 있을 것이다. 

$$
error(a, b) = \min_{a,b}\sum_{i=1}^n(Y_i - (ax_i + b))^2
$$

- 그럼 우리는 이 함수의 값이 가장 작아지는 a와 b를 찾고 싶은거죠
  - 함수의 값이 가장 작다는 것은 오차가 가장 작다는 의미와 동일

$$
error(a, b) = \underset{a, b}{\mathrm{argmin}}\sum_{i=1}^n(Y_i - (ax_i + b))^2
$$

- 즉, 오차함수의 함수값을 가장 작아지게 하는 인자 a와 b를 찾겠다는 거죠

- 여기서 문제는 해가 있을수도 있고, 없을수도 있다는 것
- 해가 없으면? 해에 근사하는 방법을 취하는 거죠

# 미분이란? 

- 함수의 기울기를 나타낸다. 
- 기울기는 함수의 변화량을 나타낸다. 
- 직선에서는 우리가 미분을 얘기하지 않습니다. 
- 미분을 구할 수 없어요 .. 

## 곡선에서의 변화량은? 

- 변화량은 구간에서의 직선의 기울기 이다. 
- 변화량을 측정하는 구간마다 기울기가 다르다. 
- 평균 변화량
